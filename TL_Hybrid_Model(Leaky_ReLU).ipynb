{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gh607JgAvZgc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "K.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rarfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hLiZggNvhhA",
        "outputId": "9b8176bf-14b2-4a57-aba9-71d2df472814"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import rarfile\n",
        "import os\n",
        "\n",
        "# Correct URL after permissions are updated\n",
        "url = 'https://drive.google.com/uc?id=1FAUSzwEDHfLN_McqFpQ6a3VWoc6h9qgw'\n",
        "output_rar = '/content/WHEAT.rar'\n",
        "\n",
        "# Download the RAR file\n",
        "gdown.download(url, output_rar, quiet=False)\n",
        "\n",
        "# Check if the downloaded file is valid before extracting\n",
        "if os.path.exists(output_rar):\n",
        "    try:\n",
        "        # Try to open the downloaded file as a RAR file\n",
        "        with rarfile.RarFile(output_rar, 'r') as rar_ref:\n",
        "            rar_ref.extractall('/content')\n",
        "        print(\"File extracted successfully!\")\n",
        "    except rarfile.NotRarFile:\n",
        "        print(\"Error: The downloaded file is not a valid RAR archive.\")\n",
        "else:\n",
        "    print(\"Error: File not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLakVoisvkWo",
        "outputId": "735a46d6-c5fb-48a2-b281-962869381041"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1FAUSzwEDHfLN_McqFpQ6a3VWoc6h9qgw\n",
            "From (redirected): https://drive.google.com/uc?id=1FAUSzwEDHfLN_McqFpQ6a3VWoc6h9qgw&confirm=t&uuid=c7c59158-c8e9-4d42-a0bc-059a11611be5\n",
            "To: /content/WHEAT.rar\n",
            "100%|██████████| 228M/228M [00:04<00:00, 46.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File extracted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the extracted dataset folder\n",
        "\n",
        "dataset = '/content/Wheat'"
      ],
      "metadata": {
        "id": "CrgC9ujbvnyV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Conv2D, MaxPooling2D, DepthwiseConv2D, BatchNormalization, LeakyReLU, Concatenate\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Directory for dataset\n",
        "data_dir = dataset  # Replace with your actual dataset path\n",
        "\n",
        "# Function to create InceptionV3 architecture with Transfer Learning\n",
        "def inceptionv3_base(input_shape=(224, 224, 3)):\n",
        "    # Load Pretrained InceptionV3 Model\n",
        "    base_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Freeze base model layers\n",
        "    for layer in base_model.layers[:249]:\n",
        "        layer.trainable = False\n",
        "    for layer in base_model.layers[249:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    # Extract features\n",
        "    x = base_model.output\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    return Model(base_model.input, x)\n",
        "\n",
        "# Function to create Custom-CNN from scratch\n",
        "def custom_cnn_base(input_shape=(224, 224, 3)):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Depthwise Separable Convolution Blocks\n",
        "    x = DepthwiseConv2D((3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = Conv2D(64, (1, 1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = DepthwiseConv2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = Conv2D(128, (1, 1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Global Average Pooling at the end\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs, x)\n",
        "\n",
        "# Build the feature extraction parts\n",
        "inception_base = inceptionv3_base(input_shape=(224, 224, 3))\n",
        "custom_cnn_base = custom_cnn_base(input_shape=(224, 224, 3))\n",
        "\n",
        "# Define input\n",
        "inputs = layers.Input(shape=(224, 224, 3))\n",
        "\n",
        "# Extract features from both models\n",
        "inception_features = inception_base(inputs)\n",
        "custom_cnn_features = custom_cnn_base(inputs)\n",
        "\n",
        "# Concatenate both feature vectors\n",
        "x = Concatenate()([inception_features, custom_cnn_features])\n",
        "\n",
        "# Fully connected layers\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "outputs = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Create hybrid model with transfer learning\n",
        "hybrid_model = Model(inputs, outputs)\n",
        "\n",
        "# Compile the hybrid model\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Image Data Generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Data Generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'train'),\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'validation'),\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'test'),\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Train the hybrid model\n",
        "history = hybrid_model.fit(train_generator, epochs=50, validation_data=val_generator)\n",
        "\n",
        "# Evaluate model on test data\n",
        "def evaluate_model(test_generator, model, classes, title=\"Performance\"):\n",
        "    y_test_pred = model.predict(test_generator)\n",
        "    y_test_pred = np.argmax(y_test_pred, axis=1)\n",
        "\n",
        "    precision = precision_score(test_generator.labels, y_test_pred, average='weighted')\n",
        "    recall = recall_score(test_generator.labels, y_test_pred, average='weighted')\n",
        "    f1 = f1_score(test_generator.labels, y_test_pred, average='weighted')\n",
        "    accuracy = accuracy_score(test_generator.labels, y_test_pred)\n",
        "\n",
        "    print(f\"\\n{title}\")\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "    # Display confusion matrix\n",
        "    confusion = confusion_matrix(test_generator.labels, y_test_pred)\n",
        "    confusion_df = pd.DataFrame(confusion, index=classes, columns=classes)\n",
        "    print(\"Confusion Matrix:\\n\", confusion_df)\n",
        "\n",
        "# Test the hybrid model on test set\n",
        "evaluate_model(test_generator, hybrid_model, ['Brown_Rust', 'Healthy', 'Yellow_Rust'], title=\"Performance on Test Data\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjDZkQO4vrf2",
        "outputId": "c9ae38e7-99a4-4681-dbbc-fe33af62d53e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4204 images belonging to 3 classes.\n",
            "Found 598 images belonging to 3 classes.\n",
            "Found 1198 images belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 355ms/step - accuracy: 0.8051 - loss: 0.4618 - val_accuracy: 0.8963 - val_loss: 0.2540\n",
            "Epoch 2/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 0.9900 - loss: 0.0336 - val_accuracy: 0.9548 - val_loss: 0.1283\n",
            "Epoch 3/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.9966 - loss: 0.0103 - val_accuracy: 0.9666 - val_loss: 0.1129\n",
            "Epoch 4/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 123ms/step - accuracy: 0.9969 - loss: 0.0126 - val_accuracy: 0.9666 - val_loss: 0.1239\n",
            "Epoch 5/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 134ms/step - accuracy: 0.9992 - loss: 0.0042 - val_accuracy: 0.9732 - val_loss: 0.1032\n",
            "Epoch 6/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - accuracy: 0.9969 - loss: 0.0078 - val_accuracy: 0.9615 - val_loss: 0.1608\n",
            "Epoch 7/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - accuracy: 0.9983 - loss: 0.0069 - val_accuracy: 0.9615 - val_loss: 0.1394\n",
            "Epoch 8/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 128ms/step - accuracy: 0.9977 - loss: 0.0079 - val_accuracy: 0.9666 - val_loss: 0.1252\n",
            "Epoch 9/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 127ms/step - accuracy: 0.9924 - loss: 0.0138 - val_accuracy: 0.9482 - val_loss: 0.2233\n",
            "Epoch 10/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 128ms/step - accuracy: 0.9901 - loss: 0.0295 - val_accuracy: 0.9632 - val_loss: 0.1245\n",
            "Epoch 11/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.9955 - loss: 0.0118 - val_accuracy: 0.9799 - val_loss: 0.0897\n",
            "Epoch 12/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9961 - loss: 0.0137 - val_accuracy: 0.9732 - val_loss: 0.1280\n",
            "Epoch 13/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9954 - loss: 0.0122 - val_accuracy: 0.9816 - val_loss: 0.1122\n",
            "Epoch 14/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.9971 - loss: 0.0054 - val_accuracy: 0.9632 - val_loss: 0.1781\n",
            "Epoch 15/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9985 - loss: 0.0072 - val_accuracy: 0.9816 - val_loss: 0.0828\n",
            "Epoch 16/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 130ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 0.9666 - val_loss: 0.1105\n",
            "Epoch 17/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 131ms/step - accuracy: 0.9971 - loss: 0.0062 - val_accuracy: 0.9849 - val_loss: 0.0652\n",
            "Epoch 18/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9799 - val_loss: 0.0881\n",
            "Epoch 19/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 132ms/step - accuracy: 0.9956 - loss: 0.0124 - val_accuracy: 0.9816 - val_loss: 0.0761\n",
            "Epoch 20/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9987 - loss: 0.0069 - val_accuracy: 0.9716 - val_loss: 0.0891\n",
            "Epoch 21/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9978 - loss: 0.0082 - val_accuracy: 0.9732 - val_loss: 0.0826\n",
            "Epoch 22/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9749 - val_loss: 0.0998\n",
            "Epoch 23/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.9992 - loss: 0.0064 - val_accuracy: 0.9799 - val_loss: 0.0941\n",
            "Epoch 24/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.9649 - val_loss: 0.1964\n",
            "Epoch 25/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9952 - loss: 0.0139 - val_accuracy: 0.9732 - val_loss: 0.1618\n",
            "Epoch 26/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 132ms/step - accuracy: 0.9995 - loss: 0.0038 - val_accuracy: 0.9766 - val_loss: 0.1175\n",
            "Epoch 27/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9979 - loss: 0.0068 - val_accuracy: 0.9732 - val_loss: 0.1293\n",
            "Epoch 28/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.9699 - val_loss: 0.1510\n",
            "Epoch 29/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9973 - loss: 0.0097 - val_accuracy: 0.9816 - val_loss: 0.0936\n",
            "Epoch 30/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.9783 - val_loss: 0.0826\n",
            "Epoch 31/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 139ms/step - accuracy: 0.9992 - loss: 0.0022 - val_accuracy: 0.9699 - val_loss: 0.1558\n",
            "Epoch 32/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9959 - loss: 0.0134 - val_accuracy: 0.9783 - val_loss: 0.1338\n",
            "Epoch 33/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - accuracy: 0.9945 - loss: 0.0130 - val_accuracy: 0.9783 - val_loss: 0.1034\n",
            "Epoch 34/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9973 - loss: 0.0048 - val_accuracy: 0.9849 - val_loss: 0.0768\n",
            "Epoch 35/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9816 - val_loss: 0.0864\n",
            "Epoch 36/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.9999 - loss: 3.6119e-04 - val_accuracy: 0.9816 - val_loss: 0.0888\n",
            "Epoch 37/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9833 - val_loss: 0.0909\n",
            "Epoch 38/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9990 - loss: 0.0012 - val_accuracy: 0.9799 - val_loss: 0.0941\n",
            "Epoch 39/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9965 - loss: 0.0136 - val_accuracy: 0.9749 - val_loss: 0.1151\n",
            "Epoch 40/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9978 - loss: 0.0064 - val_accuracy: 0.9816 - val_loss: 0.0957\n",
            "Epoch 41/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 4.0209e-04 - val_accuracy: 0.9816 - val_loss: 0.0980\n",
            "Epoch 42/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 5.0728e-04 - val_accuracy: 0.9849 - val_loss: 0.1011\n",
            "Epoch 43/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9993 - loss: 8.4078e-04 - val_accuracy: 0.9833 - val_loss: 0.0928\n",
            "Epoch 44/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.9982 - loss: 0.0039 - val_accuracy: 0.9732 - val_loss: 0.1582\n",
            "Epoch 45/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9966 - loss: 0.0168 - val_accuracy: 0.9649 - val_loss: 0.2192\n",
            "Epoch 46/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.9967 - loss: 0.0082 - val_accuracy: 0.9833 - val_loss: 0.1972\n",
            "Epoch 47/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9970 - loss: 0.0235 - val_accuracy: 0.9799 - val_loss: 0.1274\n",
            "Epoch 48/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9979 - loss: 0.0046 - val_accuracy: 0.9916 - val_loss: 0.0792\n",
            "Epoch 49/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9988 - loss: 0.0024 - val_accuracy: 0.9900 - val_loss: 0.1338\n",
            "Epoch 50/50\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 131ms/step - accuracy: 0.9975 - loss: 0.0071 - val_accuracy: 0.9799 - val_loss: 0.1240\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 314ms/step\n",
            "\n",
            "Performance on Test Data\n",
            "Precision: 0.9751386473879301\n",
            "Recall: 0.9749582637729549\n",
            "F1 Score: 0.9749527248212234\n",
            "Accuracy: 0.9749582637729549\n",
            "Confusion Matrix:\n",
            "              Brown_Rust  Healthy  Yellow_Rust\n",
            "Brown_Rust          392        4            4\n",
            "Healthy               5      392            1\n",
            "Yellow_Rust          10        6          384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model weights with the correct naming convention\n",
        "weights_path = \"/content/hybrid_model_weights.weights.h5\"  # File name ending with .weights.h5\n",
        "hybrid_model.save_weights(weights_path)\n",
        "print(f\"Weights saved to {weights_path}\")\n",
        "\n",
        "# Download the weights file\n",
        "from google.colab import files\n",
        "files.download(weights_path)  # Ensure the correct file path\n"
      ],
      "metadata": {
        "id": "GAQmTPuNa8wR",
        "outputId": "707e2790-a181-423c-8638-156b86ca0bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights saved to /content/hybrid_model_weights.weights.h5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_52d82a98-0b3d-4740-9eaf-29c68a98ab1f\", \"hybrid_model_weights.weights.h5\", 6322648)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}