{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOlfM8D7418Y",
        "outputId": "ba006c68-6318-44b8-922a-3b41604edce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: tflite-runtime in /usr/local/lib/python3.11/dist-packages (2.14.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from tflite-runtime) (1.26.4)\n",
            "Predicted Class: Brown Rust\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Install TensorFlow Lite\n",
        "!pip install tflite-runtime\n",
        "\n",
        "# Step 3: Import Required Libraries\n",
        "import numpy as np\n",
        "import tensorflow.lite as tflite\n",
        "from PIL import Image\n",
        "\n",
        "# Step 4: Define Paths (Update with your actual filenames)\n",
        "MODEL_PATH = \"/content/wheat_leaf_disease_model (2).tflite\"  # Update your model file name\n",
        "IMAGE_PATH = \"/content/Brown_rust006_aug_523.jpg\"  # Update your test image file name\n",
        "\n",
        "# Step 5: Load TFLite Model\n",
        "interpreter = tflite.Interpreter(model_path=MODEL_PATH)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Step 6: Get Model Input/Output Details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Step 7: Load and Preprocess Image\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).resize((224, 224))  # Resize to model input size\n",
        "    image = np.array(image, dtype=np.float32) / 255.0  # Normalize (0-1)\n",
        "    image = np.expand_dims(image, axis=0)  # Convert to (1, 224, 224, 3)\n",
        "    return image\n",
        "\n",
        "input_data = preprocess_image(IMAGE_PATH)\n",
        "\n",
        "# Step 8: Run Inference\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "interpreter.invoke()\n",
        "\n",
        "# Step 9: Get Prediction\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "predicted_class = np.argmax(output_data)  # Get class index\n",
        "\n",
        "# Step 10: Define Class Labels\n",
        "CLASS_LABELS = [\"Brown Rust\", \"Healthy\", \"Yellow Rust\"]  # Adjust if needed\n",
        "\n",
        "# Step 11: Print Prediction\n",
        "print(f\"Predicted Class: {CLASS_LABELS[predicted_class]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Conv2D, MaxPooling2D, DepthwiseConv2D, BatchNormalization, LeakyReLU, Concatenate\n",
        "import os\n",
        "\n",
        "# Function to create InceptionV3 architecture with Transfer Learning\n",
        "def inceptionv3_base(input_shape=(224, 224, 3)):\n",
        "    base_model = tf.keras.applications.InceptionV3(weights=None, include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(base_model.input, x)\n",
        "\n",
        "# Function to create Custom-CNN from scratch\n",
        "def custom_cnn_base(input_shape=(224, 224, 3)):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = DepthwiseConv2D((3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = Conv2D(64, (1, 1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = DepthwiseConv2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = Conv2D(128, (1, 1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs, x)\n",
        "\n",
        "# Build model\n",
        "inception_base = inceptionv3_base(input_shape=(224, 224, 3))\n",
        "custom_cnn_base = custom_cnn_base(input_shape=(224, 224, 3))\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "inception_features = inception_base(inputs)\n",
        "custom_cnn_features = custom_cnn_base(inputs)\n",
        "x = Concatenate()([inception_features, custom_cnn_features])\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "outputs = Dense(3, activation='softmax')(x)\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# Load weights\n",
        "weights_path = \"/content/hybrid_model_weights.weights (3).h5\"  # Update path\n",
        "model.load_weights(weights_path)\n",
        "print(\"✅ Weights loaded successfully!\")\n",
        "\n",
        "# Function to preprocess image\n",
        "def preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img) / 255.0  # Normalize\n",
        "    return np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "# Test the model\n",
        "def predict(img_path):\n",
        "    img_array = preprocess_image(img_path)\n",
        "    preds = model.predict(img_array)\n",
        "    class_names = ['Healthy', 'Yellow Rust', 'Brown Rust']  # Update class labels if needed\n",
        "    predicted_class = class_names[np.argmax(preds)]\n",
        "    print(f\"Predicted Class: {predicted_class}\")\n",
        "\n",
        "# Run test\n",
        "image_path = \"/content/Yellow_rust069.jpg\"  # Update with your test image path\n",
        "predict(image_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "collapsed": true,
        "id": "2NdIZhiM7Tns",
        "outputId": "82b6db5d-f359-4c0d-c3de-d5987704e0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Layer count mismatch when loading weights from file. Model expected 4 layers, found 0 saved layers.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-471da78c10cc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Load weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mweights_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/hybrid_model_weights.weights (3).h5\"\u001b[0m  \u001b[0;31m# Update path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Weights loaded successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, model)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0mlayer_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_layer_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0;34m\"Layer count mismatch when loading weights from file. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;34mf\"Model expected {len(filtered_layers)} layers, found \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 4 layers, found 0 saved layers."
          ]
        }
      ]
    }
  ]
}